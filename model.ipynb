{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "home_folder = environ.get('HOME')\n",
    "WORKSPACE = f'{home_folder}/Skin_Diseases_Detection'\n",
    "DATASET_FOLDER = f\"{home_folder}/skdi_dataset\"\n",
    "TRAINING_FOLDER = f'{DATASET_FOLDER}/Training'\n",
    "TESTING_FOLDER = f'{DATASET_FOLDER}/Testing'\n",
    "CHECKPOINT_FOLDER = f'{WORKSPACE}/checkpoints'\n",
    "STATUS_FOLDER = f'{WORKSPACE}/status'\n",
    "PLOT_FOLDER = f'{WORKSPACE}/plots'\n",
    "PARAM_FOLDER = f'{WORKSPACE}/param'\n",
    "CONFIG_FOLDER = f'{WORKSPACE}/config'\n",
    "\n",
    "from paths import TRAINING_FOLDER, TESTING_FOLDER\n",
    "import torchvision.transforms.v2 as tf\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import os\n",
    "\n",
    "workers = os.cpu_count()\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, train_trans, test_trans, train_batch_size = 32, val_rat = 0.2):\n",
    "        self._ds = ImageFolder(TRAINING_FOLDER, train_trans)\n",
    "        self.test_ds = ImageFolder(TESTING_FOLDER, test_trans)\n",
    "        ds_size = len(self._ds)\n",
    "        val_size = int(val_rat*ds_size)\n",
    "        train_size = len(self._ds) - val_size\n",
    "\n",
    "        self.train_ds, self.val_ds = Subset(self._ds, range(train_size)), Subset(self._ds, range(train_size, ds_size))\n",
    "        self.train_dl = DataLoader(self.train_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "        self.test_dl = DataLoader(self.test_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "        self.val_dl = DataLoader(self.val_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "def make_cnn(dataset: ImageFolder, hid_layers = [64, 64],\n",
    "            act_fn='relu', max_pool = None, pooling_after_layers = 2,\n",
    "            conv_layers=[[32, 3, 1],\n",
    "                         [16, 3, 1]]):\n",
    "    \n",
    "    img = dataset.__getitem__(0)[0]\n",
    "    input_shape = img.shape\n",
    "    num_of_classes = len(dataset.classes)\n",
    "    layers = []\n",
    "    activation_fun = {'relu': nn.ReLU(), 'softplus':nn.Softplus(), 'tanh':nn.Tanh(), 'elu': nn.ELU()}\n",
    "\n",
    "    assert pooling_after_layers < len(conv_layers), 'exceeding the number conv layers..'\n",
    "\n",
    "    in_chann, inp_h, inp_w = input_shape\n",
    "    for ind, conv in enumerate(conv_layers):\n",
    "        out_chann, filter_size, stride = conv\n",
    "        layers.append(nn.Conv2d(in_chann, out_chann, filter_size, stride))\n",
    "        layers.append(activation_fun[act_fn])\n",
    "\n",
    "        out_h = (inp_h - filter_size)//stride + 1\n",
    "        out_w = (inp_w - filter_size)//stride + 1\n",
    "        inp_h = out_h\n",
    "        inp_w = out_w\n",
    "\n",
    "        if max_pool is not None and ((ind+1) % pooling_after_layers == 0 or ind == (len(conv_layers) - 1)):\n",
    "            layers.append(nn.MaxPool2d(max_pool[0], max_pool[1]))\n",
    "            out_h = (inp_h - max_pool[0])//max_pool[1] + 1\n",
    "            out_w = (inp_w - max_pool[0])//max_pool[1] + 1\n",
    "            inp_h = out_h\n",
    "            inp_w = out_w\n",
    "        in_chann = out_chann\n",
    "\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(inp_h*inp_w*in_chann, hid_layers[0]))\n",
    "    layers.append(activation_fun[act_fn])\n",
    "\n",
    "    \n",
    "    if len(hid_layers) > 1:\n",
    "        dim_pairs = zip(hid_layers[:-1], hid_layers[1:])\n",
    "        for in_dim, out_dim in list(dim_pairs):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            layers.append(activation_fun[act_fn])\n",
    "\n",
    "    layers.append(nn.Linear(hid_layers[-1], num_of_classes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "from torchvision import disable_beta_transforms_warning\n",
    "disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as tf\n",
    "from utils import convert\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from paths import CHECKPOINT_FOLDER\n",
    "import yaml\n",
    "\n",
    "def convert(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "class Utils:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_file = ''\n",
    "        self.plot_file = ''\n",
    "        self.min_loss = 0\n",
    "\n",
    "    def read_file(self, path):\n",
    "        file = open(path, 'r')\n",
    "        file.seek(0)\n",
    "        info = file.readline()\n",
    "        file.close()\n",
    "        return info\n",
    "\n",
    "    def write_file(self, path, content):\n",
    "        mode = 'w'\n",
    "        if path == self.plot_file:\n",
    "            mode = '+a'\n",
    "        file = open(path, mode=mode)\n",
    "        file.write(content)\n",
    "        file.close()\n",
    "\n",
    "    def create_file(self, path):\n",
    "        with open(path, 'w') as file:\n",
    "            pass\n",
    "        file.close()\n",
    "\n",
    "    def create_checkpoint_file(self, num):\n",
    "        path = f'{CHECKPOINT_FOLDER}/checkpoint_{num}.pth'\n",
    "        file = open(path, 'w')\n",
    "        file.close()\n",
    "        return path\n",
    "    \n",
    "    def save_config(self, args: dict):\n",
    "        if not os.path.exists(self.config_file):\n",
    "            self.create_file(self.config_file)\n",
    "        with open(self.config_file, 'w') as file:\n",
    "            yaml.safe_dump(args, file)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "    def check_status_file(self):\n",
    "        if not os.path.exists(self.status_file):\n",
    "            self.create_file(self.status_file)\n",
    "        checkpath = self.read_file(self.status_file)\n",
    "        epoch = 0\n",
    "        if checkpath != '':\n",
    "            epoch = self.load_checkpoint(checkpath)\n",
    "            file = open(self.plot_file, 'r')\n",
    "            lines = file.readlines()\n",
    "            file = open(self.plot_file, 'w')\n",
    "            file.writelines(lines[:epoch+1])\n",
    "            file.close()\n",
    "        else:\n",
    "            file = open(self.plot_file, 'w')\n",
    "            file.close()\n",
    "            self.write_file(self.plot_file,'Train_loss,Train_acc,Valid_loss,Valid_acc\\n')\n",
    "            self.model.train()\n",
    "        return epoch\n",
    "\n",
    "    def write_plot_data(self, data:list):\n",
    "        str_data = ','.join(map(str, data))\n",
    "        self.write_file(self.plot_file, f'{str_data}\\n')\n",
    "\n",
    "    def save_checkpoint(self, epoch, checkpath):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optim_state_dict': self.optim.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        file = open(self.status_file, 'w')\n",
    "        file.write(checkpath)\n",
    "        file.close()\n",
    "        torch.save(checkpoint, checkpath)\n",
    "        print('checkpoint saved..')\n",
    "    \n",
    "    def load_checkpoint(self, checkpath):\n",
    "        print('loading checkpoint..')\n",
    "        checkpoint = torch.load(checkpath)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        self.model.train()\n",
    "        print('checkpoint loaded...')\n",
    "        return checkpoint['epoch']\n",
    "    \n",
    "    def save_check_interval(self, epoch, interval=50):\n",
    "        if not(epoch % interval) and epoch > 0:\n",
    "            checkpath = self.create_checkpoint_file(epoch)\n",
    "            self.save_checkpoint(epoch, checkpath)\n",
    "    \n",
    "    def load_model(self):\n",
    "        print('loading model...')\n",
    "        self.model.load_state_dict(torch.load(self.model_file))\n",
    "        self.model.eval()\n",
    "        print('model loaded...')\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.model_file)\n",
    "        print('model saved...')\n",
    "\n",
    "    def save_best_model(self, param, acc_param=True):\n",
    "        if acc_param:\n",
    "           param_ = max(param, self.param)\n",
    "        else:\n",
    "            param_ = min(param, self.param)\n",
    "        self.param = param_\n",
    "        self.write_file(self.param_file, f'{param_}')\n",
    "        self.save_model()\n",
    "\n",
    "    def check_param_file(self):\n",
    "        if os.path.exists(self.param_file):\n",
    "            param = float(self.read_file(self.param_file))\n",
    "        else:\n",
    "            self.create_file(self.param_file)\n",
    "            param = -1000.0\n",
    "            self.write_file(self.param_file, f'{param}')\n",
    "        return param\n",
    "\n",
    "\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.name = 'model'\n",
    "        self.conv_layers = [[128, 3, 1],\n",
    "                            [64, 3, 1],\n",
    "                            [32, 3, 1],\n",
    "                            [16, 3, 1]]\n",
    "        self.hid_layers = [1024, 512]\n",
    "        self.max_pool = [2, 2]\n",
    "        self.pool_after_layers = 2\n",
    "        self.act_fn = 'relu'\n",
    "        self.lr = 1e-6\n",
    "        self.epochs = 150\n",
    "        self.clip_grad = 0.5\n",
    "        self.metric_param = 'val_acc'\n",
    "        self.batch_size = 32\n",
    "        self.test_trans = tf.Compose([\n",
    "            tf.Resize(size = (256,256))\n",
    "        ])\n",
    "        self.train_trans = tf.Compose([\n",
    "            tf.Resize(size=(256, 256)),\n",
    "            tf.ToImageTensor(),\n",
    "            tf.ConvertImageDtype()\n",
    "        ])\n",
    "        self.val_rat = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
