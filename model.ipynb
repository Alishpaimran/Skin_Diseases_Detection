{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda, number of workers: 8\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchvision import disable_beta_transforms_warning\n",
    "disable_beta_transforms_warning()\n",
    "import torchvision.transforms.v2 as tf\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision import models\n",
    "\n",
    "workers = os.cpu_count()\n",
    "pu = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "assert pu == 'cuda', 'Connect to the GPU'\n",
    "\n",
    "print(f'using {pu}, number of workers: {workers}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_folder = '/home/user'\n",
    "WORKSPACE = f'{home_folder}/Skin_Diseases_Detection'\n",
    "DATASET_FOLDER = f\"{home_folder}/skdi_dataset\"\n",
    "TRAINING_FOLDER = f'{DATASET_FOLDER}/Training'\n",
    "TESTING_FOLDER = f'{DATASET_FOLDER}/Testing'\n",
    "CHECKPOINT_FOLDER = f'{WORKSPACE}/checkpoints'\n",
    "STATUS_FOLDER = f'{WORKSPACE}/status'\n",
    "PLOT_FOLDER = f'{WORKSPACE}/plots'\n",
    "PARAM_FOLDER = f'{WORKSPACE}/param'\n",
    "CONFIG_FOLDER = f'{WORKSPACE}/config'\n",
    "MODEL_FOLDER = f'{WORKSPACE}/model'\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, train_trans, test_trans, train_batch_size = 32, val_rat = 0.2):\n",
    "        self._ds = ImageFolder(TRAINING_FOLDER, train_trans)\n",
    "        self.test_ds = ImageFolder(TESTING_FOLDER, test_trans)\n",
    "        ds_size = len(self._ds)\n",
    "        val_size = int(val_rat*ds_size)\n",
    "        train_size = len(self._ds) - val_size\n",
    "\n",
    "        self.train_ds, self.val_ds = Subset(self._ds, range(train_size)), Subset(self._ds, range(train_size, ds_size))\n",
    "        self.train_dl = DataLoader(self.train_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "        self.test_dl = DataLoader(self.test_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "        self.val_dl = DataLoader(self.val_ds, batch_size=train_batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "def make_cnn(dataset: ImageFolder, hid_layers = [64, 64],\n",
    "            act_fn='relu', max_pool = None, pooling_after_layers = 2, dropout = 0.2, batch_norm=True,\n",
    "            conv_layers=[[32, 3, 1],\n",
    "                         [16, 3, 1]]):\n",
    "    \n",
    "    img = dataset.__getitem__(0)[0]\n",
    "    input_shape = img.shape\n",
    "    num_of_classes = len(dataset.classes)\n",
    "    layers = []\n",
    "    activation_fun = {'relu': nn.ReLU(), 'softplus':nn.Softplus(), 'tanh':nn.Tanh(), 'elu': nn.ELU()}\n",
    "\n",
    "    assert pooling_after_layers < len(conv_layers), 'exceeding the number conv layers..'\n",
    "\n",
    "    in_chann, inp_h, inp_w = input_shape\n",
    "    for ind, conv in enumerate(conv_layers):\n",
    "        out_chann, filter_size, stride = conv\n",
    "        layers.append(nn.Conv2d(in_chann, out_chann, filter_size, stride))\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_chann))\n",
    "        layers.append(activation_fun[act_fn])\n",
    "\n",
    "        out_h = (inp_h - filter_size)//stride + 1\n",
    "        out_w = (inp_w - filter_size)//stride + 1\n",
    "        inp_h = out_h\n",
    "        inp_w = out_w\n",
    "\n",
    "        if max_pool is not None and ((ind+1) % pooling_after_layers == 0 or ind == (len(conv_layers) - 1)):\n",
    "            layers.append(nn.MaxPool2d(max_pool[0], max_pool[1]))\n",
    "            out_h = (inp_h - max_pool[0])//max_pool[1] + 1\n",
    "            out_w = (inp_w - max_pool[0])//max_pool[1] + 1\n",
    "            inp_h = out_h\n",
    "            inp_w = out_w\n",
    "        in_chann = out_chann\n",
    "\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(inp_h*inp_w*in_chann, hid_layers[0]))\n",
    "    layers.append(activation_fun[act_fn])\n",
    "    if len(hid_layers) > 1:\n",
    "        dim_pairs = zip(hid_layers[:-1], hid_layers[1:])\n",
    "        for in_dim, out_dim in list(dim_pairs):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if dropout is not None:\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "            layers.append(activation_fun[act_fn])\n",
    "\n",
    "    layers.append(nn.Linear(hid_layers[-1], num_of_classes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def convert(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "class Utils:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_file = ''\n",
    "        self.plot_file = ''\n",
    "        self.min_loss = 0\n",
    "\n",
    "    def read_file(self, path):\n",
    "        file = open(path, 'r')\n",
    "        file.seek(0)\n",
    "        info = file.readline()\n",
    "        file.close()\n",
    "        return info\n",
    "\n",
    "    def write_file(self, path, content):\n",
    "        mode = 'w'\n",
    "        if path == self.plot_file:\n",
    "            mode = '+a'\n",
    "        file = open(path, mode=mode)\n",
    "        file.write(content)\n",
    "        file.close()\n",
    "\n",
    "    def create_file(self, path):\n",
    "        with open(path, 'w') as file:\n",
    "            pass\n",
    "        file.close()\n",
    "\n",
    "    def create_checkpoint_file(self, num):\n",
    "        path = f'{CHECKPOINT_FOLDER}/checkpoint_{num}.pth'\n",
    "        file = open(path, 'w')\n",
    "        file.close()\n",
    "        return path\n",
    "    \n",
    "    def save_config(self, args: dict):\n",
    "        if not os.path.exists(self.config_file):\n",
    "            self.create_file(self.config_file)\n",
    "        with open(self.config_file, 'w') as file:\n",
    "            yaml.safe_dump(args, file)\n",
    "        file.close()\n",
    "\n",
    "    def check_status_file(self):\n",
    "        if not os.path.exists(self.status_file):\n",
    "            self.create_file(self.status_file)\n",
    "        checkpath = self.read_file(self.status_file)\n",
    "        epoch = 0\n",
    "        if checkpath != '':\n",
    "            epoch = self.load_checkpoint(checkpath)\n",
    "            file = open(self.plot_file, 'r')\n",
    "            lines = file.readlines()\n",
    "            file = open(self.plot_file, 'w')\n",
    "            file.writelines(lines[:epoch+1])\n",
    "            file.close()\n",
    "        else:\n",
    "            file = open(self.plot_file, 'w')\n",
    "            file.close()\n",
    "            self.write_file(self.plot_file,'Train_loss,Train_acc,Valid_loss,Valid_acc\\n')\n",
    "            self.model.train()\n",
    "        return epoch\n",
    "\n",
    "    def write_plot_data(self, data:list):\n",
    "        str_data = ','.join(map(str, data))\n",
    "        self.write_file(self.plot_file, f'{str_data}\\n')\n",
    "\n",
    "    def save_checkpoint(self, epoch, checkpath):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optim_state_dict': self.optim.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        file = open(self.status_file, 'w')\n",
    "        file.write(checkpath)\n",
    "        file.close()\n",
    "        torch.save(checkpoint, checkpath)\n",
    "        print('checkpoint saved..')\n",
    "    \n",
    "    def load_checkpoint(self, checkpath):\n",
    "        print('loading checkpoint..')\n",
    "        checkpoint = torch.load(checkpath)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        self.model.train()\n",
    "        print('checkpoint loaded...')\n",
    "        return checkpoint['epoch']\n",
    "    \n",
    "    def save_check_interval(self, epoch, interval=50):\n",
    "        if not(epoch % interval) and epoch > 0:\n",
    "            checkpath = self.create_checkpoint_file(epoch)\n",
    "            self.save_checkpoint(epoch, checkpath)\n",
    "    \n",
    "    def load_model(self):\n",
    "        print('loading model...')\n",
    "        self.model.load_state_dict(torch.load(self.model_file))\n",
    "        self.model.eval()\n",
    "        print('model loaded...')\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.model_file)\n",
    "        print('model saved...')\n",
    "\n",
    "    def save_best_model(self, param, acc_param=True):\n",
    "        if acc_param:\n",
    "           param_ = max(param, self.param)\n",
    "        else:\n",
    "            param_ = min(param, self.param)\n",
    "        self.param = param_\n",
    "        self.write_file(self.param_file, f'{param_}')\n",
    "        self.save_model()\n",
    "\n",
    "    def check_param_file(self):\n",
    "        if os.path.exists(self.param_file):\n",
    "            param = float(self.read_file(self.param_file))\n",
    "        else:\n",
    "            self.create_file(self.param_file)\n",
    "            param = -1000.0\n",
    "            self.write_file(self.param_file, f'{param}')\n",
    "        return param\n",
    "    \n",
    "\n",
    "class skdi_detector(Utils):\n",
    "    def __init__(self,params):\n",
    "        self.params = params\n",
    "        self.dataset = Dataset(train_trans=params.train_trans, test_trans=params.test_trans,\n",
    "                               train_batch_size=params.batch_size, val_rat=params.val_rat)\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.name = params.name\n",
    "        self.model_file = f'{MODEL_FOLDER}/{self.name}_model.pth'\n",
    "        self.status_file = f'{STATUS_FOLDER}/{self.name}_status.txt'\n",
    "        self.plot_file = f'{PLOT_FOLDER}/{self.name}_plot.txt'\n",
    "        self.param_file = f'{PARAM_FOLDER}/{self.name}_param.txt'\n",
    "        self.config_file = f'{CONFIG_FOLDER}/{self.name}_config.yaml'\n",
    "        self.param = self.check_param_file()\n",
    "        self.metric_param = params.metric_param\n",
    "        self.clip_grad = params.clip_grad\n",
    "        self.acc_param = False\n",
    "        if self.metric_param in ['train_acc', 'val_acc']:\n",
    "            self.acc_param = True\n",
    "\n",
    "    def train_step(self):\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        for _, (x, y) in enumerate(self.dataset.train_dl):\n",
    "            x, y = x.to(pu), y.to(pu)\n",
    "            y_pred_logits = self.model(x)\n",
    "\n",
    "            loss = self.loss_fn(y_pred_logits, y)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad.clip_grad_norm_(self.model.parameters(), self.clip_grad)\n",
    "            self.optim.step()\n",
    "\n",
    "            y_pred = torch.argmax(torch.softmax(y_pred_logits, dim=-1), dim=-1)\n",
    "            train_acc += (y_pred == y).sum().item()/len(y)\n",
    "        \n",
    "        train_loss /= len(self.dataset.train_dl)\n",
    "        train_acc /= len(self.dataset.train_dl)\n",
    "\n",
    "        return train_loss, train_acc\n",
    "    \n",
    "    def validate_step(self):\n",
    "        val_loss, val_acc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for _, (x, y) in enumerate(self.dataset.val_dl):\n",
    "                x, y = x.to(pu), y.to(pu)\n",
    "                y_pred_logits = self.model(x)\n",
    "\n",
    "                loss = self.loss_fn(y_pred_logits, y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                y_pred = torch.argmax(torch.softmax(y_pred_logits, dim=-1), dim=-1)\n",
    "                val_acc += (y_pred == y).sum().item()/len(y)\n",
    "        \n",
    "        val_loss /= len(self.dataset.val_dl)\n",
    "        val_acc /= len(self.dataset.val_dl)\n",
    "        return val_loss, val_acc\n",
    "    \n",
    "    def create_model(self):\n",
    "        self.model = make_cnn(dataset=self.dataset._ds, hid_layers=self.params.hid_layers, act_fn=self.params.act_fn,\n",
    "                              max_pool=self.params.max_pool, pooling_after_layers=self.params.pool_after_layers,\n",
    "                              batch_norm=self.params.batch_norm, conv_layers=self.params.conv_layers, dropout=self.params.dropout).to(pu)\n",
    "        \n",
    "        self.optim = Adam(self.model.parameters(), lr=self.params.lr, eps=1e-6, weight_decay=1e-5)\n",
    "        print(f'Model: {self.model}')\n",
    "        print(f'Number of classes: {self.dataset._ds.classes}')\n",
    "        print(f'Input image size: {self.dataset._ds.__getitem__(0)[0][0].shape}')\n",
    "        \n",
    "    def plot_images(self):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "        for i in range(3):\n",
    "            ind = random.randint(0, len(self.dataset.train_ds)-1)\n",
    "            img = self.dataset.train_ds.__getitem__(ind)[0]\n",
    "            img = img.numpy()\n",
    "            img = img.transpose((1, 2, 0)) if img.shape[0] == 3 else img\n",
    "            axes.flat[i].imshow(img)\n",
    "            axes.flat[i].axis('off')\n",
    "\n",
    "    def train(self):\n",
    "        epochs = self.params.epochs\n",
    "        epoch = 0\n",
    "        epoch = self.check_status_file()\n",
    "        print(f'training for {epochs} epochs....')\n",
    "        for ep in tqdm(range(epoch, epochs+1)):\n",
    "            train_loss, train_acc = self.train_step()\n",
    "            val_loss, val_acc = self.validate_step()\n",
    "\n",
    "            metric_param = {'train_loss': train_loss, 'train_acc': train_acc,\n",
    "                            'val_loss': val_loss, 'val_acc': val_acc}\n",
    "            \n",
    "            print(f'epochs: {ep}\\t{train_loss = :.4f}\\t{train_acc = :.4f}\\t{val_loss = :.4f}\\t{val_acc = :.4f}')\n",
    "            self.write_plot_data([train_loss, train_acc, val_loss, val_acc])\n",
    "            self.save_check_interval(epoch=ep, interval=1)\n",
    "            self.save_best_model(acc_param=self.acc_param, param=metric_param[self.metric_param])\n",
    "        \n",
    "        print('Finished Training....')\n",
    "    \n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.name = 'model'\n",
    "        self.transfer_learn = True\n",
    "        if self.transfer_learn:\n",
    "            self.tl_weights = models.ResNet101_Weights.DEFAULT\n",
    "            self.tl_model = models.resnet101(weights=self.tl_weights)\n",
    "        else:\n",
    "            self.conv_layers = [[128, 3, 1],\n",
    "                                [128, 3, 1],\n",
    "                                [64, 3, 1],\n",
    "                                [64, 3, 1],\n",
    "                                [32, 3, 1],\n",
    "                                [32, 3, 1],\n",
    "                                [16, 3, 1],\n",
    "                                [16, 3, 1]]\n",
    "            self.max_pool = [2, 2]\n",
    "            self.pool_after_layers = 2\n",
    "            self.act_fn = 'relu'\n",
    "            self.batch_norm = True\n",
    "            self.dropout = 0.2\n",
    "        self.hid_layers = [1024, 512, 256]\n",
    "        self.lr = 1e-5\n",
    "        self.epochs = 100\n",
    "        self.clip_grad = 0.3\n",
    "        self.metric_param = 'val_acc'\n",
    "        self.batch_size = 16\n",
    "        self.test_trans = tf.Compose([\n",
    "            tf.Resize(size = (256,256)),\n",
    "            tf.ToTensor(),\n",
    "            tf.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.train_trans = tf.Compose([\n",
    "            tf.Resize(size=(256, 256)),\n",
    "            tf.RandomHorizontalFlip(p=0.7),\n",
    "            tf.RandomVerticalFlip(p=0.6),\n",
    "            tf.ToTensor(),\n",
    "            tf.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.val_rat = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Sequential(\n",
      "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU()\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU()\n",
      "  (17): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (18): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU()\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (22): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): ReLU()\n",
      "  (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU()\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Flatten(start_dim=1, end_dim=-1)\n",
      "  (29): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "  (30): ReLU()\n",
      "  (31): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (32): Dropout(p=0.2, inplace=False)\n",
      "  (33): ReLU()\n",
      "  (34): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (35): Dropout(p=0.2, inplace=False)\n",
      "  (36): ReLU()\n",
      "  (37): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "Number of classes: ['akiec', 'mel', 'nv']\n",
      "Input image size: torch.Size([256, 256])\n",
      "training dataset size: 399\n",
      "validation dataset size: 99\n"
     ]
    }
   ],
   "source": [
    "params = Params()\n",
    "\n",
    "agent = skdi_detector(params)\n",
    "\n",
    "agent.create_model()\n",
    "print(f'training dataset size: {len(agent.dataset.train_ds)}')\n",
    "print(f'validation dataset size: {len(agent.dataset.val_ds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = Params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
